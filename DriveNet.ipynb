{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.preprocessing import image\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 320, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenet_1.00_160 (Model)   (None, 5, 5, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6553856   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,817,281\n",
      "Trainable params: 6,587,649\n",
      "Non-trainable params: 3,229,632\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.mobilenet import decode_predictions, preprocess_input\n",
    "from keras.layers import Input, Lambda, Flatten, Dense, Dropout, Cropping2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "TARGET_SHAPE = (160, 160)\n",
    "TARGET_SIZE = (TARGET_SHAPE[0] + 160, TARGET_SHAPE[1])\n",
    "BATCH_SIZE=128\n",
    "\n",
    "def make_model():\n",
    "    x = Input(shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3))\n",
    "    cropped = Cropping2D(((120, 40), (0, 0)))(x)\n",
    "    preprocessed = Lambda(lambda x: preprocess_input(x))(cropped)\n",
    "    base_model = MobileNet(alpha=1.0, include_top=False, input_shape=(TARGET_SHAPE[0], TARGET_SHAPE[1], 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model_out = base_model(preprocessed)\n",
    "    flatten = Flatten()(model_out)\n",
    "    dense1 = Dense(256, activation=\"elu\")(flatten)\n",
    "    norm1 = Dropout(0.2)(\n",
    "        BatchNormalization()(dense1))\n",
    "    dense2 = Dense(128, activation=\"elu\")(norm1)\n",
    "    norm2 = Dropout(0.2)(\n",
    "        BatchNormalization()(dense2))\n",
    "    dense3 = Dense(1)(norm2)\n",
    "    \n",
    "    model = Model(x, dense3)\n",
    "    return model\n",
    "\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "def _make_generator(df, batch_size=BATCH_SIZE):\n",
    "    batch_X = []\n",
    "    batch_y = []\n",
    "    while True:\n",
    "        for i, row in df.sample(frac=1.).iterrows():\n",
    "            img = image.load_img(row[0], target_size=TARGET_SIZE)\n",
    "            if row['flipped']:\n",
    "                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                batch_y.append(-row[3])\n",
    "            else:\n",
    "                batch_y.append(row[3])\n",
    "                \n",
    "            batch_X.append(image.img_to_array(img))\n",
    "            \n",
    "            if len(batch_X) >= batch_size:\n",
    "                yield np.array(batch_X, dtype=np.float32), np.array(batch_y, dtype=np.float32)\n",
    "                batch_X = []\n",
    "                batch_y = []\n",
    "\n",
    "        if batch_X:\n",
    "            yield np.array(batch_X, dtype=np.float32), np.array(batch_y, dtype=np.float32)\n",
    "            batch_X = []\n",
    "            batch_y = []\n",
    "\n",
    "\n",
    "def _load_path(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data['flipped'] = np.zeros(len(data), dtype=np.bool)\n",
    "    flipped_data = pd.read_csv(path)\n",
    "    flipped_data['flipped'] = np.ones(len(flipped_data), dtype=np.bool)\n",
    "    data = data.append(flipped_data)\n",
    "    \n",
    "    def _make_full_path(x):\n",
    "        try:\n",
    "            return os.path.join(os.path.dirname(path), x)\n",
    "        except AttributeError:\n",
    "            return x\n",
    "\n",
    "    data = data.applymap(_make_full_path)\n",
    "    return data\n",
    "\n",
    "def data_generators(paths):\n",
    "    data = pd.concat(_load_path(p) for p in paths)\n",
    "    rnd = np.random.rand(len(data))\n",
    "    train = data[rnd < 0.7]\n",
    "    validation = data[(rnd >=0.7) & (rnd < 0.9)]\n",
    "    test = data[rnd >= 0.9]\n",
    "    \n",
    "    return {\n",
    "        \"train\": (len(train), _make_generator(train)),\n",
    "        \"valid\": (len(validation), _make_generator(validation)),\n",
    "        \"test\": (len(test), _make_generator(test))\n",
    "    }\n",
    "\n",
    "generators = data_generators([\n",
    "    \"/home/orazaev/workspace/data/data/driving_log.csv\",\n",
    "    \"/home/orazaev/workspace/data/curves_data/driving_log.csv\",\n",
    "    \"/home/orazaev/workspace/data/bridge/driving_log.csv\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "159/158 [==============================] - 166s - loss: 0.6242 - val_loss: 0.0478\n",
      "Epoch 2/15\n",
      "159/158 [==============================] - 165s - loss: 0.2294 - val_loss: 0.0205\n",
      "Epoch 3/15\n",
      "159/158 [==============================] - 163s - loss: 0.1175 - val_loss: 0.0145\n",
      "Epoch 4/15\n",
      "159/158 [==============================] - 163s - loss: 0.0614 - val_loss: 0.0121\n",
      "Epoch 5/15\n",
      "159/158 [==============================] - 165s - loss: 0.0335 - val_loss: 0.0127\n",
      "Epoch 6/15\n",
      "159/158 [==============================] - 164s - loss: 0.0213 - val_loss: 0.0128\n",
      "Epoch 7/15\n",
      "159/158 [==============================] - 164s - loss: 0.0157 - val_loss: 0.0119\n",
      "Epoch 8/15\n",
      "159/158 [==============================] - 164s - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 9/15\n",
      "159/158 [==============================] - 164s - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 10/15\n",
      "159/158 [==============================] - 164s - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 11/15\n",
      "159/158 [==============================] - 164s - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 12/15\n",
      "159/158 [==============================] - 164s - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 13/15\n",
      "159/158 [==============================] - 164s - loss: 0.0088 - val_loss: 0.0113\n",
      "Epoch 14/15\n",
      "159/158 [==============================] - 164s - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 15/15\n",
      "159/158 [==============================] - 163s - loss: 0.0076 - val_loss: 0.0118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe156ddfba8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "train_size, train_gen = generators[\"train\"]\n",
    "valid_size, valid_gen = generators[\"valid\"]\n",
    "model.fit_generator(train_gen, train_size / BATCH_SIZE, epochs=15, validation_data=valid_gen, validation_steps=valid_size / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011815854086438952"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size, test_gen = generators[\"test\"]\n",
    "model.evaluate_generator(test_gen, test_size / 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"drivenet.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
